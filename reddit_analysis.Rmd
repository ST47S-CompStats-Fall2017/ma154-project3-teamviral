---
title: "Investigating the Popularity of Scientific Phenomena on Social Media Platforms"
output:
  pdf_document: default
  html_document: default
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, message=FALSE, warning=FALSE, cache=TRUE, 
                      fig.width=7, fig.height=3, fig.align = "center")
```

##Motivation

Large numbers of scientific studies are published each day, many of which address pertinent gaps in human knowledge. Some results, however, become much more visible to the general populace than others. Why do some scientific results go viral, while others remain obscure? We wish to investigate what factors might influence the popularity of links about science on a social media platform, and the insights that may lend to scientific communication.

We choose Reddit as our platform for analysis because it is the 8th most visited site around the world, with over 500 million users total. This particular platform is convenient because it has a specific forum, the "Science" subreddit, that is dedicated to sharing and discussing scientific results. This particular subreddit can also reach a broad viewership because all Reddit users are subscribed to it by default (at the time this was written, the "Science" subreddit has around 18 million subscribers). 

On Reddit, users can post content and "Upvote" the posts that they like. Within a subreddit, posts with higher upvotes will end up on the first page of the subreddit (e.g. they are the first posts that users will see when they visit the subreddit). When a post in "Science" gathers enough votes, it will end up on the "Reddit" frontpage, where it will get an even large viewership (all Reddit users will see the post when they open the website?). 

For this work, we will use "Upvotes" as our metric of whether a scientific article is popular: e.g., our response variable. We plan to use methods of statistical inference to understand which variables may contribute the most to whether a scientific article garners a large number of upvotes. 

## Data Wrangling

Using the Python Reddit API Wrapper, we obtain data about individual posts in the "Science" subreddit ranging back atwo years. We select the number of upvotes that a post has, as that will be our metric of popularity. We then select columns that contain information about what we believe will be relevant variables in assessing a post's popularity: among some are the length of the post title, the time at which the post was created, the amount of "karma" the post author has, and the number of comments on the post. We also define a variable called the "journal $h$ index", which tracks posts containing scientific articles that are deemed "high-impact."

We store the resulting dataframe in "reddit_df.csv", and read it in below: 

```{r}
#Read the reddit data into a dataframe
library(readr)
require(ggplot2)
reddit_df <- read_csv("reddit_df_sent.csv")
#Store a copy of the dataframe for later use
reddit_df_read <- reddit_df
```

After retrieving the data, we take multiple steps to wrangle it into a format that makes more sense given the variables we are trying to investigate. The data for "Time" that we retrieve from is in units of seconds elapsed from January 1st, 1970 in UTC time. We use the code below to translate that metric of time into year, date, and hour.

##Modifications to Date Column

```{r}
require(lubridate)
require(dplyr)

#Store all of the POSIX dates into a vector
dates <- as.POSIXct(reddit_df$created_utc,origin = "1970-01-01",tz = "UTC")

#Use lubridate to read y,m,d,h from that vector. Create new columns for these
reddit_df <- reddit_df %>%  
  mutate(post_year = year(dates),post_month = month(dates), post_day = day(dates), post_hour = hour(dates))
```

After obtaining that information, we create a categorical variable for "time" to categorize the time of day that the post was created into "Day", "Morning", and "Night". This step was necessary because otherwise, the classification algorithm would not classify "23" and "0" as the same portion of the day (time wise), which would change with our results. 

```{r}
#Create a new column for categorical time of day
#Time ranges: PST 6pm-3am night      3am-10am morning    11am-6pm day
mk_cat_time <- function(h)
{
  ifelse(h>18, "night", ifelse(h>10, "day", ifelse(h>2, "morning", "night")))
}

#Create a new column for categorical time of month
#Time ranges: 1-10 early    11-20 mid    21-31 late
mk_cat_day <- function(d)
{
  ifelse(d>20, "late", ifelse(d>10, "mid", "early"))
}

#Create a new column for categorical time of year
#Time ranges: Dec-Feb: Winter   Mar-May: Spring    Jun-Aug: Summer    Sep-Nov: Fall
mk_cat_month <- function(m)
{
  ifelse(m>11, "Winter", ifelse(m>8, "Fall", ifelse(m>5, "Summer", ifelse(m>2, "Spring", "Winter"))))
}

reddit_df <- reddit_df %>%
  mutate(cat_post_hour = mk_cat_time(post_hour)) %>%
  mutate(cat_post_day = mk_cat_day(post_day)) %>%
  mutate(cat_post_month = mk_cat_month(post_month)) 
```

Next, we clean up the data in order to remove posts that do not share scientific content (e.g. AMAs, subreddit discussions) by filtering under the subfield column. 

```{r}
library(stringr)

#Filter by removing the Ask Me Anything (AMA) threads and the subreddit discussion
  #threads since these are not studies. 
reddit_df <- reddit_df %>%
  filter(!str_detect(subfield, " AMA")) %>%
  filter(subfield != "Subreddit Discussion") %>%
  filter(subfield != "Subreddit Feature") %>%
  filter(subfield != "Deaths + injuries") %>%
  filter(subfield != "Mathematics")

#Display the remaining subfields
count(reddit_df,subfield)
```

Now, we group the remaining subfields into four major categories so that our model can more easily divide among them. We made these selections by our impressions of the categories that these fields fall into, so this step is certainly subjective. 

```{r}
#Make a function that sorts fields into "Life Science," "Psychology," "Physical Science," "Environment"
mk_cat_subfield <- function(field)
{
  ifelse(field == "Biology" | field =="Health" | field =="Cancer" | field =="Medicine" | field =="Animal Science" | field =="Paleontology" | field =="Epidemiology", "Life Science", ifelse(field =="Psychology" | field =="Neuroscience" | field =="Social Science" | field =="Anthropology", "Psychology", ifelse(field =="Geology" | field =="Astronomy" | field =="Physics" | field =="Chemistry" | field =="Nanoscience" | field =="Engineering" | field =="Computer Science", "Physical Science", "Environment")))
}
#Apply the function and remove the old column
reddit_df <- reddit_df %>%
  mutate(cat_subfield = mk_cat_subfield(subfield)) %>%
  select(-subfield)

#Turn the new column into a factor for model use
reddit_df$cat_subfield <- factor(reddit_df$cat_subfield)
```

Here we make a plot of the distribution of articles into these four categories, saved as subfield_chart.png

```{r}
subfield_freq = table(reddit_df$cat_subfield)
type_freq_perc = paste(round((subfield_freq/(237+1100+360+497))*100,0), "%",sep="")
type_freq_lab = paste(c("Environment","Life science", "Physical science", "Psychology"), type_freq_perc, sep = " ")
png("subfield_chart.png", width=8, height=6, units="in", res=500)
pie(subfield_freq,labels=type_freq_lab, init.angle = 51, edges = 10000, col = c("paleturquoise3","darkseagreen4","slateblue4","plum2"), main="Distribution of Subfields")
dev.off()
```

```{r}
#Turn all categorical variables into factors
reddit_df$author_flair_binary <- factor(reddit_df$author_flair_binary)
reddit_df$image <- factor(reddit_df$image)
reddit_df$journal_h_index <- factor(reddit_df$journal_h_index)
reddit_df$post_year <- factor(reddit_df$post_year)
reddit_df$cat_post_month <- factor(reddit_df$cat_post_month)
reddit_df$cat_post_hour <- factor(reddit_df$cat_post_hour)
reddit_df$cat_post_day <- factor(reddit_df$cat_post_day)
```

Author created date vs upvotes -- bias from single high-karma user 'mvea'. Thus we removed this observations posted by this user from the data.

```{r}
acd_plot <- ggplot(data=reddit_df, aes(x=author_created_date, y=upvotes))+
  geom_point(size=0.5) +
  xlab("Author Creation Date")+
  ylab("Upvotes")+
  ggtitle("Upvotes v.s. Author Creation Date")
#ggsave(acd_plot, filename='./acd_plot.png', width=8, height=5)

acd_plot
```

Number of comments vs upvotes -- expected strong positive correlation. Coupled with response.

```{r}
nc_plot <- ggplot(data=reddit_df, aes(x=num_comments, y=upvotes))+
  geom_point(size=0.5) +
  xlab("Number of Comments")+
  ylab("Upvotes")+
  ggtitle("Upvotes v.s. Number of Comments")
#ggsave(nc_plot, filename='./nc_plot.png', width=8, height=5)

nc_plot
```

```{r}
#To prepare for model building, we remove unnecessary columns and ones correlated with response
reddit_df <- reddit_df %>%
  select(-X1,-author,-id,-created_utc,-domain,-url,-author_flair,-post_day,-post_hour,-post_month,-num_comments,-gilded,-link_karma,-comment_karma,-title,-X1_1,-author_created_date)
```

Now we remove any rows that have missing values. We also print the proportion of rows removed below to ensure that we are not removing a large fraction of the data. The vast majority of these removed rows are due to authors that have since deleted their accounts, so all of their data is missing. 

```{r}
bef_rm <- nrow(reddit_df)

#Remove missing values
reddit_df <- reddit_df[complete.cases(reddit_df),]
aft_rm <- nrow(reddit_df)

paste("Proportion of rows removed: ",(bef_rm-aft_rm)/bef_rm)
```

Here we plot a histogram of the number of upvotes, showing that the vast majority of our data has "low" (<1000) upvotes:

```{r}
require(ggplot2)
hist_upvotes <- qplot(reddit_df$upvotes,
      geom="histogram",
      binwidth = 25,
      main = 'Histogram of Upvotes (Response Variable)',
      xlab = "Number of Upvotes",
      ylab = "Counts",
      fill=I("blue"),
      col=I("red"), 
      alpha=I(.2),
      xlim=c(0,2000)) +
  geom_vline(xintercept=1000,show_guide=TRUE,linetype="dashed")

hist_upvotes
#ggsave(hist_upvotes, filename='./hist_upvotes.png', width=8, height=5)
```

Here, we plot the mean title word length vs. number of upvotes: 

```{r}
mtl_plot <- ggplot(data=reddit_df, aes(x=mean_title_length, y=upvotes))+
  geom_point(size=0.5) +
  xlab("Average Word Length")+
  ylab("Upvotes")+
  ggtitle("Upvotes v.s. Average Word Length (in Title)")

mtl_plot
#ggsave(mtl_plot, filename='./mtl_plot.png', width=8, height=5)
```

Here, we plot the total title length vs. number of upvotes: 

```{r}
tl_plot <- ggplot(data=reddit_df, aes(x=title_len, y=upvotes))+
  geom_point(size=0.5) +
  xlab("Total Title Length")+
  ylab("Upvotes")+
  ggtitle("Upvotes v.s. Total Title Length")
ggsave(tl_plot, filename='./tl_plot.png', width=8, height=5)

tl_plot
```


Now we turn the continuous upvote response variable into a binary response. We choose 1000 upvotes as our cut-off, because that seems to be the approximate threshold where a post will end up on the front page of the subreddit, or the front page of the entire website.

```{r}
#Create a new column for categorical upvotes
#Ranges: 1000+ high      0+ low
mk_cat_upvotes <- function(upv)
{
  ifelse(upv>1000, "High", "Low")
}
#Apply the function and remove the old column
reddit_df <- reddit_df %>%
  mutate(cat_upvotes = mk_cat_upvotes(upvotes)) %>%
  select(-upvotes)

#Turn the column into a factor
reddit_df$cat_upvotes <- factor(reddit_df$cat_upvotes)
```


##Model Building

Finally, we are ready to build our Random Forest model. We partition the data into test and training, setting aside the test data so that we can appropriately assess our model's accuracy. 

```{r}
#Packages required for model building
require(caret)
require(rpart)

#Set the seed for reproducibility
set.seed(47)

#Split the data into test and training, with 80% going to training
inTrain <- createDataPartition(y = reddit_df$cat_upvotes, p=0.80, list=FALSE)
reddit.train <- reddit_df[inTrain,]
reddit.test <- reddit_df[-c(inTrain),]
```

By looking at the number of observations in tach category below, we see that predicting everything as "low" gives a fairly high accuracy! To avoid this, we will sample from our training set to have equal number of "high" and "low" responses. 

```{r}
#Print the number of observations in each category
sum(reddit.train['cat_upvotes'] == "High")
sum(reddit.train['cat_upvotes'] == "Low")
```

We sample from the "low" training data so that it now has the same number of observations as the high.

```{r}
### Sample data such that there is a equal number of observations for each category.

#Count the number of high upvotes
num_high_upvote <- sum(reddit.train['cat_upvotes'] == "High")

reddit.train.high <- subset(reddit.train, reddit.train['cat_upvotes'] == "High")
reddit.train.low <- subset(reddit.train, reddit.train['cat_upvotes'] == "Low")

#Select an equal proportion of high and low upvotes
inTrain.low <- createDataPartition(y = reddit.train.low$cat_upvotes, p=num_high_upvote/dim(reddit.train.low)[1], list=FALSE)
reddit.train.low <- reddit.train.low[inTrain.low,]
```

```{r}
### Combine the 2 dataframes into the final training data
reddit.train.final <- rbind(reddit.train.low, reddit.train.high)
```

```{r}
#Check that the numbers are equal.
reddit_df %>% group_by(cat_upvotes) %>% summarize(n())
```

Now we grow the random forest, using the out of bag error rate to tune the mtry parameter (number of variables at each split). 

```{r}
#Build the random forest model
set.seed(4747)

rf.reddit <- train(cat_upvotes ~., data=reddit.train.final, method="rf",
                      trControl = trainControl(method="oob"),
                      ntree=1000, tuneGrid = data.frame(mtry=c(3,5,7,9,11)),
                      importance = TRUE,na.action = na.exclude)

rf.reddit$finalModel
```

The model with the best accuracy corresponds to mtry = . Using this best model, we predict our test data to assess our model's accuracy. 

```{r}
#mean((log(reddit.test$upvotes+1) - predict(rf.reddit, newdata = reddit.test))^2)
confusionMatrix(data=predict(rf.reddit, newdata = reddit.test), reference = reddit.test$cat_upvotes)
```

Now, we print the variable importance for the model. This gives us an indication of which explanatory variables most directly impact the response. 
```{r}
varImp(rf.reddit,scale=FALSE)
```

Print the posts with the most positive title sentiments
```{r}
reddit_df_read %>%
  arrange(desc(title_sent)) %>%
  select(title_sent,title) %>%
  head()
```

Print the posts with the most negative title sentiments
```{r}
reddit_df_read %>%
  arrange(title_sent) %>%
  select(title_sent,title) %>%
  head()
```